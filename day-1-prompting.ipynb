{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"day-1-prompting.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Installing the SDK\n!pip install -U -q \"google-generativeai>=0.8.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:43:31.703014Z","iopub.execute_input":"2024-11-24T16:43:31.703917Z","iopub.status.idle":"2024-11-24T16:43:57.113928Z","shell.execute_reply.started":"2024-11-24T16:43:31.703878Z","shell.execute_reply":"2024-11-24T16:43:57.112700Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import google.generativeai as genai\nfrom IPython.display import HTML, Markdown, display","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:43:57.116374Z","iopub.execute_input":"2024-11-24T16:43:57.117331Z","iopub.status.idle":"2024-11-24T16:43:58.204129Z","shell.execute_reply.started":"2024-11-24T16:43:57.117278Z","shell.execute_reply":"2024-11-24T16:43:58.203048Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#setting up API Key\nfrom kaggle_secrets import UserSecretsClient\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key = GOOGLE_API_KEY )","metadata":{"trusted":true,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-11-24T16:43:58.205494Z","iopub.execute_input":"2024-11-24T16:43:58.205931Z","iopub.status.idle":"2024-11-24T16:43:59.241122Z","shell.execute_reply.started":"2024-11-24T16:43:58.205899Z","shell.execute_reply":"2024-11-24T16:43:59.240179Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#testing that your API is working correctly \nflash = genai.GenerativeModel(\"gemini-1.5-flash\")\nresponse = flash.generate_content(\"In simple terms, tell me what you think about Love\")\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:43:59.244072Z","iopub.execute_input":"2024-11-24T16:43:59.244532Z","iopub.status.idle":"2024-11-24T16:44:00.798533Z","shell.execute_reply.started":"2024-11-24T16:43:59.244484Z","shell.execute_reply":"2024-11-24T16:44:00.797425Z"}},"outputs":[{"name":"stdout","text":"Love is a powerful feeling that makes people feel connected and happy.  It can be between romantic partners, family members, friends, or even pets. It involves caring deeply for someone, wanting their happiness, and feeling close to them.  It's complex and can be wonderful, challenging, and everything in between.\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"Markdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:44:00.799724Z","iopub.execute_input":"2024-11-24T16:44:00.800032Z","iopub.status.idle":"2024-11-24T16:44:00.807653Z","shell.execute_reply.started":"2024-11-24T16:44:00.800001Z","shell.execute_reply":"2024-11-24T16:44:00.806544Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Love is a powerful feeling that makes people feel connected and happy.  It can be between romantic partners, family members, friends, or even pets. It involves caring deeply for someone, wanting their happiness, and feeling close to them.  It's complex and can be wonderful, challenging, and everything in between.\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"#setting up a multiturn chat structure \nchat = flash.start_chat(history = [])\nresponse = chat.send_message(\"Hello, my name is Sharbie!\")\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:44:00.809174Z","iopub.execute_input":"2024-11-24T16:44:00.809873Z","iopub.status.idle":"2024-11-24T16:44:02.035422Z","shell.execute_reply.started":"2024-11-24T16:44:00.809827Z","shell.execute_reply":"2024-11-24T16:44:02.034443Z"}},"outputs":[{"name":"stdout","text":"Hi Sharbie, it's nice to meet you!  How can I help you today?\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"response = chat.send_message(\"Can you tell me about Amsterdam? I am relocating there soon, I want to know some fascinating things about it\")\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:44:02.036750Z","iopub.execute_input":"2024-11-24T16:44:02.037187Z","iopub.status.idle":"2024-11-24T16:44:06.746408Z","shell.execute_reply.started":"2024-11-24T16:44:02.037142Z","shell.execute_reply":"2024-11-24T16:44:06.745261Z"}},"outputs":[{"name":"stdout","text":"That's exciting, Sharbie!  Relocating to Amsterdam is a fantastic adventure.  Here are some fascinating things about Amsterdam that go beyond the typical tourist highlights:\n\n**Beyond the Canals and Bikes:**\n\n* **The \"Golden Age\":** Amsterdam's history isn't just pretty canals and tulips.  The 17th century was its \"Golden Age,\" a period of incredible wealth and artistic flourishing.  Rembrandt, Vermeer, and Frans Hals all lived and worked here, leaving an indelible mark on the city's character and countless masterpieces in its museums.  Explore beyond the famous works and delve into the stories of these artists and their era.\n\n* **Hidden Churches and Chapels:** Amsterdam boasts a rich religious history, reflected in its numerous churches, many hidden away in quiet courtyards.  These often offer stunning architecture and a peaceful contrast to the bustling city life. Look for smaller, less-visited churches for a more intimate experience.\n\n* **The Begijnhof:** This secluded courtyard is a beautiful and historic oasis. It's one of the few remaining Begijnhofs (communities for lay women) in the Netherlands and offers a glimpse into a unique aspect of Amsterdam's past.  The quiet atmosphere and hidden chapel are well worth a visit.\n\n* **Street Art and Graffiti:** Amsterdam has a vibrant street art scene, with many hidden gems tucked away in less-traveled neighborhoods.  Take a walking tour or explore on your own to discover incredible murals and graffiti art.  The Jordaan district is a good place to start.\n\n* **The Vondelpark After Dark:** While the Vondelpark is beautiful during the day, it takes on a different, enchanting atmosphere at night. It's a popular spot for locals to relax, socialize, and enjoy the summer evenings.\n\n* **Indonesian Influence:** The Netherlands' colonial past in Indonesia has left a lasting impact on Amsterdam's cuisine and culture.  Explore Indonesian restaurants (Rijsttafel is a must-try!) and discover the rich blend of influences.\n\n* **The \"Nine Streets\" (De Negen Straatjes):** This charming area, nestled between the canals, is a shopper's paradise.  It's filled with independent boutiques, antique shops, and cozy cafes, offering a more authentic Amsterdam experience than the major shopping streets.\n\n* **Amsterdam's Underground:**  Beyond the canals, Amsterdam has a fascinating underground world, including old cellars, hidden passages, and even remnants of the city's medieval past.  Some of these are accessible via guided tours.\n\n**Practical tips for relocating:**\n\n* **Biking:** Learn to bike! It's the quintessential Amsterdam experience and the most efficient way to get around.\n* **Language:** While English is widely spoken, learning some basic Dutch will greatly enhance your experience and interactions with locals.\n* **Neighborhoods:** Research different neighborhoods to find the best fit for your lifestyle.  Each area has its own unique character and atmosphere.\n\n\nThis is just a starting point!  To truly appreciate Amsterdam's fascinating aspects,  explore its diverse neighborhoods, engage with the locals, and be open to discovering its hidden gems.  Enjoy your relocation!  Let me know if you have any other questions.\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"Markdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:44:06.748032Z","iopub.execute_input":"2024-11-24T16:44:06.748394Z","iopub.status.idle":"2024-11-24T16:44:06.755128Z","shell.execute_reply.started":"2024-11-24T16:44:06.748337Z","shell.execute_reply":"2024-11-24T16:44:06.754110Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"That's exciting, Sharbie!  Relocating to Amsterdam is a fantastic adventure.  Here are some fascinating things about Amsterdam that go beyond the typical tourist highlights:\n\n**Beyond the Canals and Bikes:**\n\n* **The \"Golden Age\":** Amsterdam's history isn't just pretty canals and tulips.  The 17th century was its \"Golden Age,\" a period of incredible wealth and artistic flourishing.  Rembrandt, Vermeer, and Frans Hals all lived and worked here, leaving an indelible mark on the city's character and countless masterpieces in its museums.  Explore beyond the famous works and delve into the stories of these artists and their era.\n\n* **Hidden Churches and Chapels:** Amsterdam boasts a rich religious history, reflected in its numerous churches, many hidden away in quiet courtyards.  These often offer stunning architecture and a peaceful contrast to the bustling city life. Look for smaller, less-visited churches for a more intimate experience.\n\n* **The Begijnhof:** This secluded courtyard is a beautiful and historic oasis. It's one of the few remaining Begijnhofs (communities for lay women) in the Netherlands and offers a glimpse into a unique aspect of Amsterdam's past.  The quiet atmosphere and hidden chapel are well worth a visit.\n\n* **Street Art and Graffiti:** Amsterdam has a vibrant street art scene, with many hidden gems tucked away in less-traveled neighborhoods.  Take a walking tour or explore on your own to discover incredible murals and graffiti art.  The Jordaan district is a good place to start.\n\n* **The Vondelpark After Dark:** While the Vondelpark is beautiful during the day, it takes on a different, enchanting atmosphere at night. It's a popular spot for locals to relax, socialize, and enjoy the summer evenings.\n\n* **Indonesian Influence:** The Netherlands' colonial past in Indonesia has left a lasting impact on Amsterdam's cuisine and culture.  Explore Indonesian restaurants (Rijsttafel is a must-try!) and discover the rich blend of influences.\n\n* **The \"Nine Streets\" (De Negen Straatjes):** This charming area, nestled between the canals, is a shopper's paradise.  It's filled with independent boutiques, antique shops, and cozy cafes, offering a more authentic Amsterdam experience than the major shopping streets.\n\n* **Amsterdam's Underground:**  Beyond the canals, Amsterdam has a fascinating underground world, including old cellars, hidden passages, and even remnants of the city's medieval past.  Some of these are accessible via guided tours.\n\n**Practical tips for relocating:**\n\n* **Biking:** Learn to bike! It's the quintessential Amsterdam experience and the most efficient way to get around.\n* **Language:** While English is widely spoken, learning some basic Dutch will greatly enhance your experience and interactions with locals.\n* **Neighborhoods:** Research different neighborhoods to find the best fit for your lifestyle.  Each area has its own unique character and atmosphere.\n\n\nThis is just a starting point!  To truly appreciate Amsterdam's fascinating aspects,  explore its diverse neighborhoods, engage with the locals, and be open to discovering its hidden gems.  Enjoy your relocation!  Let me know if you have any other questions.\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"response = chat.send_message(\"Hope you have not forgotten my name?\")\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:44:06.756492Z","iopub.execute_input":"2024-11-24T16:44:06.756805Z","iopub.status.idle":"2024-11-24T16:44:08.048708Z","shell.execute_reply.started":"2024-11-24T16:44:06.756776Z","shell.execute_reply":"2024-11-24T16:44:08.047620Z"}},"outputs":[{"name":"stdout","text":"My apologies, Sharbie! I haven't forgotten your name.  I'm still here to help you with anything you need regarding your move to Amsterdam.\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#choosing a model\nfor model in genai.list_models():\n    print(model.name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:44:08.053241Z","iopub.execute_input":"2024-11-24T16:44:08.053594Z","iopub.status.idle":"2024-11-24T16:44:08.896064Z","shell.execute_reply.started":"2024-11-24T16:44:08.053564Z","shell.execute_reply":"2024-11-24T16:44:08.894827Z"}},"outputs":[{"name":"stdout","text":"models/chat-bison-001\nmodels/text-bison-001\nmodels/embedding-gecko-001\nmodels/gemini-1.0-pro-latest\nmodels/gemini-1.0-pro\nmodels/gemini-pro\nmodels/gemini-1.0-pro-001\nmodels/gemini-1.0-pro-vision-latest\nmodels/gemini-pro-vision\nmodels/gemini-1.5-pro-latest\nmodels/gemini-1.5-pro-001\nmodels/gemini-1.5-pro-002\nmodels/gemini-1.5-pro\nmodels/gemini-1.5-pro-exp-0801\nmodels/gemini-1.5-pro-exp-0827\nmodels/gemini-1.5-flash-latest\nmodels/gemini-1.5-flash-001\nmodels/gemini-1.5-flash-001-tuning\nmodels/gemini-1.5-flash\nmodels/gemini-1.5-flash-exp-0827\nmodels/gemini-1.5-flash-002\nmodels/gemini-1.5-flash-8b\nmodels/gemini-1.5-flash-8b-001\nmodels/gemini-1.5-flash-8b-latest\nmodels/gemini-1.5-flash-8b-exp-0827\nmodels/gemini-1.5-flash-8b-exp-0924\nmodels/learnlm-1.5-pro-experimental\nmodels/gemini-exp-1114\nmodels/gemini-exp-1121\nmodels/embedding-001\nmodels/text-embedding-004\nmodels/aqa\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"for model in genai.list_models():\n    if model.name == \"models/gemini-1.5-flash\":\n        print(model)\n        break\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:44:08.897470Z","iopub.execute_input":"2024-11-24T16:44:08.897796Z","iopub.status.idle":"2024-11-24T16:44:09.181487Z","shell.execute_reply.started":"2024-11-24T16:44:08.897765Z","shell.execute_reply":"2024-11-24T16:44:09.180267Z"}},"outputs":[{"name":"stdout","text":"Model(name='models/gemini-1.5-flash',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.5 Flash',\n      description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n                   'fast and versatile multimodal model for scaling across diverse tasks.'),\n      input_token_limit=1000000,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=40)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"for model in genai.list_models():\n    if model.name == \"models/gemini-1.5-pro\":\n        print(model)\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:44:09.182856Z","iopub.execute_input":"2024-11-24T16:44:09.183258Z","iopub.status.idle":"2024-11-24T16:44:09.976710Z","shell.execute_reply.started":"2024-11-24T16:44:09.183213Z","shell.execute_reply":"2024-11-24T16:44:09.975635Z"}},"outputs":[{"name":"stdout","text":"Model(name='models/gemini-1.5-pro',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.5 Pro',\n      description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n                   'supports up to 2 million tokens, released in May of 2024.'),\n      input_token_limit=2000000,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=40)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"#exploring generation parameters \nshort_model = genai.GenerativeModel(\n    \"gemini-1.5-flash\",\n    generation_config = genai.GenerationConfig(max_output_tokens = 1600)\n)\nresponse = short_model.generate_content(\" In less than 1000 words, Give me break down on how I can incorporate generative AI indeveloping personalized fashion clothes for each body type\")\n\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:44:09.978421Z","iopub.execute_input":"2024-11-24T16:44:09.978723Z","iopub.status.idle":"2024-11-24T16:44:17.287204Z","shell.execute_reply.started":"2024-11-24T16:44:09.978694Z","shell.execute_reply":"2024-11-24T16:44:17.286091Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Generative AI offers exciting possibilities for personalized fashion. Here's a breakdown of how to incorporate it into developing clothes for different body types:\n\n**1. Data Acquisition and Preparation:**\n\n* **Body Scan Data:**  The foundation is high-quality 3D body scan data.  This can be obtained through:\n    * **Direct Scanning:** Using 3D body scanners in physical stores or at home (though accessibility remains a challenge).\n    * **Photogrammetry:**  Using multiple photos from different angles to create a 3D model (more accessible, but requires good lighting and consistent pose).\n    * **Data Synthesis:**  Generating synthetic body scans using generative models trained on existing datasets. This helps address privacy concerns and data scarcity for underrepresented body types.  This requires careful attention to avoid biases present in the training data.\n\n* **Clothing Data:** You'll need a substantial dataset of clothing designs, including:\n    * **2D Images:**  Photos of garments from various angles.\n    * **3D Models:**  Ideally, 3D models of garments for better fitting simulations.\n    * **Metadata:**  Crucial information like garment type, fabric properties (stretch, drape), measurements, style attributes, and customer reviews.\n\n* **Body Type Classification:** You'll need a system to categorize body types. This could be based on standard sizing charts, anthropometric measurements (height, weight, bust, waist, hip), or a more nuanced approach using body shape clustering algorithms applied to the 3D scan data.\n\n**2. Generative AI Model Selection and Training:**\n\nSeveral AI approaches can be used:\n\n* **Generative Adversarial Networks (GANs):** Excellent for generating new clothing designs based on existing ones, allowing for variations in style and details while maintaining the desired aesthetic.  You can train a GAN to generate designs specifically for different body types by feeding it paired data of body scans and corresponding garment designs.\n\n* **Variational Autoencoders (VAEs):**  VAEs can learn a latent representation of clothing designs and body shapes.  This allows you to generate variations of a design or adapt a design to a specific body type by manipulating the latent space.\n\n* **Diffusion Models:**  These models are also powerful for image generation and can be trained on the same type of data as GANs.  They often produce higher-quality and more realistic results.\n\n* **3D Generative Models:**  For more sophisticated applications, consider using 3D generative models that directly generate 3D garment models. This eliminates the need for 2D-to-3D conversion and improves accuracy for virtual fitting.\n\n\n**3. Personalized Garment Design:**\n\n* **Virtual Fitting:** Use the chosen generative model to virtually \"dress\" the 3D body scan with generated clothing designs. This allows you to preview how the garment would fit on a specific body type before manufacturing.\n\n* **Design Adaptation:**  Based on the virtual fitting, the AI can automatically adjust the garment pattern (e.g., altering sleeve length, waistline, etc.) to ensure a better fit and aesthetic appeal for each individual.\n\n* **Fabric Selection:** The AI can also suggest appropriate fabrics based on the body type and desired garment style.  For example, a stretchy fabric might be recommended for a tighter-fitting garment on a curvier body type.\n\n* **Style Recommendation:**  The system can leverage user preferences (e.g., through style questionnaires, past purchases) to generate designs that align with individual taste while ensuring a good fit.\n\n**4. Manufacturing and Delivery:**\n\n* **3D Printing:**  For highly customized garments, 3D printing offers direct-to-consumer manufacturing.  This is ideal for smaller production runs and unique designs.\n\n* **Traditional Manufacturing:** Adaptations made by the AI can inform traditional pattern cutting and sewing processes.  This enables personalization on a larger scale but with less extreme customization.\n\n**Challenges and Considerations:**\n\n* **Data Bias:**  Ensure your training data represents a diverse range of body types and avoids perpetuating existing biases in the fashion industry.\n* **Computational Cost:**  Training and running generative AI models can be computationally expensive.\n* **Explainability:**  Understanding *why* the AI makes certain design choices is important for building trust and addressing potential errors.\n* **Ethical Concerns:**  Address potential issues around data privacy, intellectual property, and the impact on garment workers.\n\n\nIn summary, integrating generative AI in personalized fashion requires a multi-stage process involving data acquisition, model selection, design generation, and manufacturing.  The key is to combine powerful AI techniques with careful consideration of ethical implications and practical limitations.  The result can be a revolutionary approach to fashion design, delivering truly personalized garments for every body type.\n"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"#exploring temperature\nfrom google.api_core import retry\nhigh_temp_model = genai.GenerativeModel(\n    \"gemini-1.5-flash\",\n    generation_config = genai.GenerationConfig(temperature = 2.0)\n)\n\n#using retry policy so that the code automatically retries when hitting resource exhausted.\n\nretry_policy ={\n    \"retry\": retry.Retry(predicate=retry.if_transient_error, initial=10, multiplier=1.5, timeout=300)\n}\n\nfor _ in range (5):\n    response = high_temp_model.generate_content(\"Pick a random color... (respond in a single word)\",\n                                              request_options=retry_policy)\n    if response.parts:\n        print(response.text, '-'*25)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:44:17.288654Z","iopub.execute_input":"2024-11-24T16:44:17.289003Z","iopub.status.idle":"2024-11-24T16:44:21.111711Z","shell.execute_reply.started":"2024-11-24T16:44:17.288969Z","shell.execute_reply":"2024-11-24T16:44:21.110590Z"}},"outputs":[{"name":"stdout","text":"Aquamarine\n -------------------------\nMaroon\n -------------------------\nAzure\n -------------------------\nAquamarine\n -------------------------\nAquamarine\n -------------------------\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"#retyring the same prompt but for low temperature \nlow_temp_model = genai.GenerativeModel(\n    \"gemini-1.5-flash\",\n    generation_config = genai.GenerationConfig(temperature = 0.0)\n)\n\n#using retry policy so that the code automatically retries when hitting resource exhausted.\n\nretry_policy ={\n    \"retry\": retry.Retry(predicate=retry.if_transient_error, initial=10, multiplier=1.5, timeout=300)\n}\n\nfor _ in range (5):\n    response = low_temp_model.generate_content(\"Pick a random color... (respond in a single word)\",\n                                              request_options=retry_policy)\n    if response.parts:\n        print(response.text, '-'*25)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:44:21.112898Z","iopub.execute_input":"2024-11-24T16:44:21.113201Z","iopub.status.idle":"2024-11-24T16:44:24.055027Z","shell.execute_reply.started":"2024-11-24T16:44:21.113172Z","shell.execute_reply":"2024-11-24T16:44:24.053880Z"}},"outputs":[{"name":"stdout","text":"Maroon\n -------------------------\nMaroon\n -------------------------\nMaroon\n -------------------------\nMaroon\n -------------------------\nMaroon\n -------------------------\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"#top-K and top-P\nmodel = genai.GenerativeModel(\n    \"gemini-1.5-flash\",\n    generation_config = genai.GenerationConfig(\n        temperature = 1.0,\n        top_k = 40,\n        top_p = 0.85,\n        \n    )\n)\n\nstory_prompt = \"You are an adventurous writer, write me a short story about an introverted girl who found freedom to travel\"\nresponse = model.generate_content(story_prompt, request_options=retry_policy)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:44:24.056330Z","iopub.execute_input":"2024-11-24T16:44:24.056694Z","iopub.status.idle":"2024-11-24T16:44:28.249455Z","shell.execute_reply.started":"2024-11-24T16:44:24.056663Z","shell.execute_reply":"2024-11-24T16:44:28.248296Z"}},"outputs":[{"name":"stdout","text":"Elara, a creature of shadows and quiet corners, lived a life measured in the rustle of turning pages and the soft click of her keyboard.  The world outside her attic room, a chaotic symphony of honking cars and boisterous laughter, was a place she observed from afar, a fascinating tapestry woven with threads she dared not touch.  Her only companions were the ghosts of Austen and Bronte, and the whispering wind that rattled the windowpanes.\n\nThen came the postcard.  A vibrant splash of turquoise water lapping at a sun-drenched beach, sent by her eccentric Aunt Esme, who'd vanished years ago to \"find herself\" in the wilds of Bali.  The postcard was a siren song, a whisper of freedom Elara hadn't known she craved.\n\nWith a tremor in her hands, she booked a one-way ticket. Bali felt like another planet, a kaleidoscope of scents and sounds that initially overwhelmed her. The bustling markets were a sensory assault, the vibrant sarongs a stark contrast to her muted wardrobe.  Yet, something shifted within her.\n\nShe started small.  A solitary hike through a rice paddy, the emerald terraces unfolding before her like a painted scroll.  The silence, devoid of the usual urban cacophony, wasn't empty; it was filled with the chirping of crickets and the gentle breeze.  She found solace in the solitude, a different kind of quiet, one that nurtured rather than suffocated.\n\nThen came the surf.  Fear, a constant companion, clawed at her as she wobbled on the board, the immense ocean a terrifying yet exhilarating force.  She fell, repeatedly, swallowing saltwater and sand, but with each wipeout, a layer of her introversion peeled away.  The ocean, she discovered, was a mirror reflecting not her anxieties, but her strength, her resilience.\n\nShe met people, too – a wizened old woman who taught her to weave intricate baskets, a group of laughing surfers who shared their passion, a kind artist who saw the quiet intensity in her eyes.  These encounters, brief as they were, were brushstrokes on the canvas of her life, adding vibrant colours to her previously monochrome existence.\n\nElara didn't conquer her introversion; she transcended it.  She learned that quiet contemplation could coexist with thrilling adventure.  She found that freedom wasn't the absence of fear, but the courage to face it, head-on, in the face of a breathtaking sunset over the Indian Ocean, the salty wind whipping through her hair.  The girl who once hid in the shadows now stood bathed in the golden light, a traveler, a storyteller, a woman finally free.\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"#prompting; trying different prompting techniques\n#first is zero shot\nmodel = genai.GenerativeModel(\n    \"gemini-1.5-flash\",\n    generation_config = genai.GenerationConfig(\n        temperature = 0.1,\n        top_p = 1,\n        max_output_tokens = 5,\n    )\n)\n\nzero_shot_prompt = \"\"\"Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE.\nReview: \"Queen of Tears\" is a Korean drama focused on how two lovers found themselves \namidst adversities. Although it was so obvious they loved each other, \nI don't know why they had to take so long to come back together to cherish \nthemselves more. I commend the lady's dresses, they were spot on.\nSentiment: \"\"\"\n\nresponse = model.generate_content(zero_shot_prompt, request_options = retry_policy)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:44:28.250946Z","iopub.execute_input":"2024-11-24T16:44:28.251316Z","iopub.status.idle":"2024-11-24T16:44:28.739421Z","shell.execute_reply.started":"2024-11-24T16:44:28.251283Z","shell.execute_reply":"2024-11-24T16:44:28.738292Z"}},"outputs":[{"name":"stdout","text":"Sentiment: **POSITIVE**\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"#using Enum Mode from gemini API to constrain the output to a fixed set of values\nimport enum\n\nclass Sentiment(enum.Enum):\n    POSITIVE = \"positive\"\n    NEUTRAL = 'neutral'\n    NEGATIVE = \"negative\"\n\nmodel = genai.GenerativeModel(\n    \"gemini-1.5-flash\",\n    generation_config = genai.GenerationConfig(\n        response_mime_type=\"text/x.enum\",\n        response_schema=Sentiment\n    )\n)\nresponse = model.generate_content(zero_shot_prompt, request_options = retry_policy)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:44:28.740805Z","iopub.execute_input":"2024-11-24T16:44:28.741201Z","iopub.status.idle":"2024-11-24T16:44:38.623553Z","shell.execute_reply.started":"2024-11-24T16:44:28.741169Z","shell.execute_reply":"2024-11-24T16:44:38.622481Z"}},"outputs":[{"name":"stdout","text":"positive\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"#zero-short - no examples ---done\n#one-shot - one example\n#few-shots - few examples\n\nmodel = genai.GenerativeModel(\n    \"gemini-1.5-flash\",\n    generation_config = genai.GenerationConfig(\n        temperature = 0.1,\n        top_p = 1,\n        max_output_tokens = 250,\n    )\n)\n\nfew_shot_prompt = \"\"\"Parse a customer's pizza order into valid JSON:\n\nEXAMPLE:\nI want a small pizza with cheese, tomato sauce, and pepperoni.\nJSON Response:\n```\n{\n\"size\": \"small\",\n\"type\": \"normal\",\n\"ingredients\": [\"cheese\", \"tomato sauce\", \"peperoni\"]\n}\n```\n\nEXAMPLE:\nCan I get a large pizza with tomato sauce, basil and mozzarella\nJSON Response:\n```\n{\n\"size\": \"large\",\n\"type\": \"normal\",\n\"ingredients\": [\"tomato sauce\", \"basil\", \"mozzarella\"]\n}\n\nORDER:\n\"\"\"\n\ncustomer_order = \"Give me a large with cheese & pineapple\"\n\nresponse = model.generate_content([few_shot_prompt, customer_order], request_options = retry_policy)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:44:38.624910Z","iopub.execute_input":"2024-11-24T16:44:38.625326Z","iopub.status.idle":"2024-11-24T16:45:00.663305Z","shell.execute_reply.started":"2024-11-24T16:44:38.625271Z","shell.execute_reply":"2024-11-24T16:45:00.662286Z"}},"outputs":[{"name":"stdout","text":"```json\n{\n  \"size\": \"large\",\n  \"type\": \"normal\",\n  \"ingredients\": [\"cheese\", \"pineapple\"]\n}\n```\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"##JSON Mode- forces the model to constrain decoding\nimport typing_extensions as typing\n\nclass PizzaOrder(typing.TypedDict):\n    size: str\n    ingredients: list[str]\n    type: str\n\nmodel = genai.GenerativeModel(\n    \"gemini-1.5-flash\",\n    generation_config = genai.GenerationConfig(\n        temperature = 0.1,\n        response_mime_type = \"application/json\",\n        response_schema = PizzaOrder,\n                          \n    )\n)\n\nresponse = model.generate_content(\"Can I have a large pineaple dessert with strawberries and apple\")\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:45:00.664547Z","iopub.execute_input":"2024-11-24T16:45:00.664823Z","iopub.status.idle":"2024-11-24T16:45:01.386565Z","shell.execute_reply.started":"2024-11-24T16:45:00.664796Z","shell.execute_reply":"2024-11-24T16:45:01.385306Z"}},"outputs":[{"name":"stdout","text":"{\"ingredients\": [\"pineapple\", \"strawberries\", \"apple\"], \"size\": \"large\", \"type\": \"dessert\"}\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"#using Chain of thought prompting\n#Chain of thought prompting involves making the model to output intermediate reasoning steps\n\nprompt = \"\"\"When I was 4 years old, my partner was 3 times my age. Now, I\nam 20 years old. How old is my partner? Return the answer directly.\"\"\"\n\nmodel = genai.GenerativeModel('gemini-1.5-flash-latest')\nresponse = model.generate_content(prompt, request_options = retry_policy)\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:45:01.387834Z","iopub.execute_input":"2024-11-24T16:45:01.388191Z","iopub.status.idle":"2024-11-24T16:45:01.864815Z","shell.execute_reply.started":"2024-11-24T16:45:01.388158Z","shell.execute_reply":"2024-11-24T16:45:01.863754Z"}},"outputs":[{"name":"stdout","text":"41\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"#this above answer is wrong, hence we will employ chain of thought method by telling it to think step by step\nprompt = \"\"\"When I was 4 years old, my partner was 3 times my age. Now, I\nam 20 years old. How old is my partner? Let's think step by step\"\"\"\n\nmodel = genai.GenerativeModel('gemini-1.5-flash-latest')\nresponse = model.generate_content(prompt, request_options = retry_policy)\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:49:14.408987Z","iopub.execute_input":"2024-11-24T16:49:14.409445Z","iopub.status.idle":"2024-11-24T16:49:15.800092Z","shell.execute_reply.started":"2024-11-24T16:49:14.409409Z","shell.execute_reply":"2024-11-24T16:49:15.798948Z"}},"outputs":[{"name":"stdout","text":"Step 1: Find the partner's age when you were 4.\n\n* You were 4, and your partner was 3 times your age, so your partner was 4 * 3 = 12 years old.\n\nStep 2: Find the age difference between you and your partner.\n\n* The age difference is 12 - 4 = 8 years.\n\nStep 3: Determine your partner's current age.\n\n* You are now 20 years old, and the age difference remains constant.  Therefore, your partner is currently 20 + 8 = 28 years old.\n\n\nTherefore, your partner is now 28 years old.\n\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"#another prompting technique is the reason and act\n\nmodel_instructions = \"\"\"\nSolve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation,\nObservation is understanding relevant information from an Action's output and Action can be one of three types:\n (1) <search>entity</search>, which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it\n     will return some similar entities to search and you can try to search the information from those topics.\n (2) <lookup>keyword</lookup>, which returns the next sentence containing keyword in the current context. This only does exact matches,\n     so keep your searches short.\n (3) <finish>answer</finish>, which returns the answer and finishes the task.\n\"\"\"\n\nexample1 = \"\"\"Question\nMusician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?\n\nThought 1\nThe question simplifies to \"The Simpsons\" character Milhouse is named after who. I only need to search Milhouse and find who it is named after.\n\nAction 1\n<search>Milhouse</search>\n\nObservation 1\nMilhouse Mussolini Van Houten is a recurring character in the Fox animated television series The Simpsons voiced by Pamela Hayden and created by Matt Groening.\n\nThought 2\nThe paragraph does not tell who Milhouse is named after, maybe I can look up \"named after\".\n\nAction 2\n<lookup>named after</lookup>\n\nObservation 2\nMilhouse was named after U.S. president Richard Nixon, whose middle name was Milhous.\n\nThought 3\nMilhouse was named after U.S. president Richard Nixon, so the answer is Richard Nixon.\n\nAction 3\n<finish>Richard Nixon</finish>\n\"\"\"\n\nexample2 = \"\"\"Question\nWhat is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\n\nThought 1\nI need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.\n\nAction 1\n<search>Colorado orogeny</search>\n\nObservation 1\nThe Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.\n\nThought 2\nIt does not mention the eastern sector. So I need to look up eastern sector.\n\nAction 2\n<lookup>eastern sector</lookup>\n\nObservation 2\nThe eastern sector extends into the High Plains and is called the Central Plains orogeny.\n\nThought 3\nThe eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.\n\nAction 3\n<search>High Plains</search>\n\nObservation 3\nHigh Plains refers to one of two distinct land regions\n\nThought 4\nI need to instead search High Plains (United States).\n\nAction 4\n<search>High Plains (United States)</search>\n\nObservation 4\nThe High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130m).\n\nThought 5\nHigh Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.\n\nAction 5\n<finish>1,800 to 7,000 ft</finish>\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:57:19.830163Z","iopub.execute_input":"2024-11-24T16:57:19.830630Z","iopub.status.idle":"2024-11-24T16:57:19.837582Z","shell.execute_reply.started":"2024-11-24T16:57:19.830594Z","shell.execute_reply":"2024-11-24T16:57:19.836568Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"question = \"\"\"Question\nWho was the youngest star in the Merlin series\n\"\"\"\n\nmodel = genai.GenerativeModel('gemini-1.5-flash-latest')\nreact_chat = model.start_chat()\n\n# You will perform the Action, so generate up to, but not including, the Observation.\nconfig = genai.GenerationConfig(stop_sequences=[\"\\nObservation\"])\n\n\nresp = react_chat.send_message(\n    [model_instructions, example1, example2, question],\n    generation_config=config,\n    request_options=retry_policy)\nprint(resp.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:01:04.521719Z","iopub.execute_input":"2024-11-24T17:01:04.522174Z","iopub.status.idle":"2024-11-24T17:01:08.487498Z","shell.execute_reply.started":"2024-11-24T17:01:04.522140Z","shell.execute_reply":"2024-11-24T17:01:08.486423Z"}},"outputs":[{"name":"stdout","text":"Thought 1\nI need to search for the Merlin series and find the actors' ages.  This will require multiple searches or a broader search that lists the cast.\n\nAction 1\n<search>Merlin (TV series) cast</search>\n\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"#code prompting\n\ncode_prompt = \"\"\" Write a Python code to compute the factorial of a number. \n                  No explanation is needed, provide only the code\"\"\"\n\nmodel = genai.GenerativeModel(\n    'gemini-1.5-flash-latest',\n    generation_config = genai.GenerationConfig(\n        temperature = 1,\n        top_p = 1,\n        max_output_tokens = 1024,\n        \n    )\n    \n)\nresponse = model.generate_content(code_prompt, request_options = retry_policy)\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:10:11.827696Z","iopub.execute_input":"2024-11-24T17:10:11.828135Z","iopub.status.idle":"2024-11-24T17:10:13.076881Z","shell.execute_reply.started":"2024-11-24T17:10:11.828100Z","shell.execute_reply":"2024-11-24T17:10:13.075871Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"```python\ndef factorial(n):\n  if n == 0:\n    return 1\n  else:\n    return n * factorial(n-1)\n```\n"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"#code excecution\n\ncode_exec_prompt = \"\"\"\nCalculate the sum of the first 14 prime numbers. Only consider the odd primes, and make sure you count them all.\n\"\"\"\n\nmodel = genai.GenerativeModel(\n    'gemini-1.5-flash-latest',\n    tools = 'code_execution',\n)\nresponse = model.generate_content(code_exec_prompt, request_options = retry_policy)\n\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:20:53.587876Z","iopub.execute_input":"2024-11-24T17:20:53.588301Z","iopub.status.idle":"2024-11-24T17:21:01.135529Z","shell.execute_reply.started":"2024-11-24T17:20:53.588265Z","shell.execute_reply":"2024-11-24T17:21:01.134466Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"To calculate the sum of the first 14 odd prime numbers, I will first generate a list of prime numbers and then sum the first 14 odd primes from that list.  I will exclude 2, the only even prime number.\n\n\n``` python\nimport sympy\n\ndef is_prime(n):\n    \"\"\"Checks if a number is prime using sympy.\"\"\"\n    return sympy.isprime(n)\n\nprimes = []\nnum = 2\ncount = 0\nwhile count < 14:\n    if is_prime(num) and num % 2 != 0:  #Check if it's odd and prime\n        primes.append(num)\n        count += 1\n    num += 1\n\nsum_of_primes = sum(primes)\nprint(f'{primes=}')\nprint(f'{sum_of_primes=}')\n\n```\n```\nprimes=[3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]\nsum_of_primes=326\n\n```\nThe first 14 odd prime numbers are 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, and 47.  Their sum is 326.\n"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"#explaining code\nfile_contents = !curl https://raw.githubusercontent.com/magicmonty/bash-git-prompt/refs/heads/master/gitprompt.sh\n\nexplain_prompt = f\"\"\"\nPlease explain what this file does at a very high level. What is it, and why would I use it?\n\n```\n{file_contents}\n```\n\"\"\"\n\nmodel = genai.GenerativeModel('gemini-1.5-flash-latest')\n\nresponse = model.generate_content(explain_prompt, request_options=retry_policy)\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:23:55.726959Z","iopub.execute_input":"2024-11-24T17:23:55.727348Z","iopub.status.idle":"2024-11-24T17:23:59.344486Z","shell.execute_reply.started":"2024-11-24T17:23:55.727318Z","shell.execute_reply":"2024-11-24T17:23:59.343313Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"This file is a bash script that enhances your command-line prompt to display information about your current Git repository.  Think of it as a highly customizable Git status indicator for your terminal.\n\n**What it does at a high level:**\n\nThe script adds information to your shell prompt (PS1), such as:\n\n* **Current Git branch:**  Shows the name of the branch you're working on.\n* **Ahead/Behind status:** Indicates if your local branch is ahead of or behind the remote branch.\n* **Uncommitted changes:** Shows if you have uncommitted changes, staged changes, or conflicts.\n* **Customizable theme:** Allows you to change the colors and appearance of the prompt.\n* **Optional features:**  Includes options to show username/repo, virtual environment, and more.\n\n**Why you would use it:**\n\nThis script improves your workflow by providing at-a-glance information about your Git repository without needing to run `git status` every time. This makes it quicker to see your repository's state and understand where you are in your development process.  It's especially helpful when working on multiple projects simultaneously.\n"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}